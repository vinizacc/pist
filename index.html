<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>PC Audio Stream to iPhone</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/socket.io/4.7.2/socket.io.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <style>
        .gradient-bg {
            background: linear-gradient(135deg, #6e8efb, #a777e3);
        }
        .device-card {
            transition: all 0.3s ease;
            box-shadow: 0 10px 20px rgba(0,0,0,0.1);
        }
        .device-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 15px 30px rgba(0,0,0,0.2);
        }
        .pulse {
            animation: pulse 2s infinite;
        }
        @keyframes pulse {
            0% { box-shadow: 0 0 0 0 rgba(74, 144, 226, 0.7); }
            70% { box-shadow: 0 0 0 10px rgba(74, 144, 226, 0); }
            100% { box-shadow: 0 0 0 0 rgba(74, 144, 226, 0); }
        }
        .audio-visualizer {
            height: 60px;
            background: linear-gradient(90deg, rgba(255,255,255,0.1) 0%, rgba(255,255,255,0.3) 50%, rgba(255,255,255,0.1) 100%);
            border-radius: 10px;
            position: relative;
            overflow: hidden;
        }
        .audio-bar {
            position: absolute;
            bottom: 0;
            width: 4px;
            background-color: white;
            border-radius: 2px;
            animation: equalize 1.5s infinite ease-in-out;
        }
        @keyframes equalize {
            0%, 100% { height: 10%; }
            50% { height: 90%; }
        }
        .warning-box {
            animation: pulse-warning 2s infinite;
        }
        @keyframes pulse-warning {
            0% { box-shadow: 0 0 0 0 rgba(255, 193, 7, 0.7); }
            70% { box-shadow: 0 0 0 10px rgba(255, 193, 7, 0); }
            100% { box-shadow: 0 0 0 0 rgba(255, 193, 7, 0); }
        }
    </style>
</head>
<body class="gradient-bg min-h-screen text-white">
    <div class="container mx-auto px-4 py-8">
        <header class="text-center mb-12">
            <h1 class="text-4xl font-bold mb-2">PC Audio Stream to iPhone</h1>
            <p class="text-xl opacity-90">Stream your PC's audio output to your iPhone in real-time</p>
        </header>

        <div class="flex flex-col lg:flex-row justify-center gap-8 mb-12">
            <!-- PC Device Card -->
            <div id="pc-card" class="device-card bg-white/10 backdrop-blur-md rounded-xl p-6 w-full lg:w-1/3">
                <div class="flex items-center mb-4">
                    <i class="fas fa-desktop text-3xl mr-3"></i>
                    <h2 class="text-2xl font-semibold">Windows PC</h2>
                </div>
                <div class="audio-visualizer mb-6 flex items-end justify-around" id="pc-visualizer">
                    <!-- Audio bars will be added by JavaScript -->
                </div>
                <div class="space-y-4">
                    <button id="pc-start" class="w-full bg-blue-500 hover:bg-blue-600 text-white py-3 px-4 rounded-lg font-medium transition">
                        <i class="fas fa-play mr-2"></i> Start Streaming
                    </button>
                    <button id="pc-stop" disabled class="w-full bg-gray-500 text-white py-3 px-4 rounded-lg font-medium transition">
                        <i class="fas fa-stop mr-2"></i> Stop Streaming
                    </button>
                    <div class="warning-box bg-yellow-500/20 p-3 rounded-lg text-sm flex items-start">
                        <i class="fas fa-exclamation-triangle mt-1 mr-2"></i>
                        <span>For system audio capture, use Chrome/Edge on Windows with <a href="chrome://flags/#enable-experimental-web-platform-features" class="underline" target="_blank">Experimental Web Platform Features</a> enabled</span>
                    </div>
                </div>
            </div>

            <!-- Connection Status -->
            <div class="flex flex-col justify-center items-center my-4 lg:my-0">
                <div id="connection-status" class="bg-white/10 backdrop-blur-md rounded-full p-4 mb-4 text-center">
                    <i class="fas fa-plug text-3xl"></i>
                    <p class="mt-2">Not Connected</p>
                </div>
                <div id="room-control" class="bg-white/10 backdrop-blur-md rounded-xl p-4 w-full">
                    <div class="mb-3">
                        <label for="room-id" class="block mb-1">Room ID</label>
                        <input type="text" id="room-id" placeholder="Enter room ID" class="bg-white/20 text-white rounded px-3 py-2 w-full">
                    </div>
                    <button id="join-room" class="w-full bg-purple-500 hover:bg-purple-600 text-white py-2 px-4 rounded-lg font-medium transition">
                        <i class="fas fa-door-open mr-2"></i> Join Room
                    </button>
                </div>
            </div>

            <!-- iPhone Device Card -->
            <div id="iphone-card" class="device-card bg-white/10 backdrop-blur-md rounded-xl p-6 w-full lg:w-1/3">
                <div class="flex items-center mb-4">
                    <i class="fas fa-mobile-alt text-3xl mr-3"></i>
                    <h2 class="text-2xl font-semibold">iPhone</h2>
                </div>
                <div class="audio-visualizer mb-6 flex items-end justify-around" id="iphone-visualizer">
                    <!-- Audio bars will be added by JavaScript -->
                </div>
                <div class="space-y-4">
                    <button id="iphone-start" class="w-full bg-blue-500 hover:bg-blue-600 text-white py-3 px-4 rounded-lg font-medium transition">
                        <i class="fas fa-play mr-2"></i> Start Listening
                    </button>
                    <button id="iphone-stop" disabled class="w-full bg-gray-500 text-white py-3 px-4 rounded-lg font-medium transition">
                        <i class="fas fa-stop mr-2"></i> Stop Listening
                    </button>
                    <div class="flex items-center">
                        <i class="fas fa-volume-up mr-2"></i>
                        <input type="range" id="volume-control" min="0" max="1" step="0.1" value="0.7" class="w-full">
                    </div>
                </div>
            </div>
        </div>

        <div class="bg-white/10 backdrop-blur-md rounded-xl p-6 max-w-3xl mx-auto">
            <h3 class="text-xl font-semibold mb-4 flex items-center">
                <i class="fas fa-info-circle mr-2"></i> How It Works
            </h3>
            <ol class="list-decimal list-inside space-y-2">
                <li><strong>On Windows PC:</strong> Enable <a href="chrome://flags/#enable-experimental-web-platform-features" class="underline" target="_blank">Experimental Web Platform Features</a> in Chrome/Edge</li>
                <li>Enter a Room ID and click "Join Room" on both devices</li>
                <li>On your Windows PC, click "Start Streaming" to capture system audio</li>
                <li>On your iPhone, click "Start Listening" to receive the audio stream</li>
                <li>Adjust volume on your iPhone using the volume slider</li>
                <li>Click "Stop Streaming" or "Stop Listening" to end the session</li>
            </ol>
            <div class="mt-6 p-4 bg-blue-500/20 rounded-lg flex items-start">
                <i class="fas fa-lightbulb mt-1 mr-3"></i>
                <p>For best results, use Chrome or Edge on Windows (with experimental flag enabled) and Safari on iPhone. The first time you start streaming, you'll need to select "System Audio" in the browser's permission dialog.</p>
            </div>
        </div>
    </div>

    <script>
        // Initialize variables
        let audioContext;
        let mediaStreamDestination;
        let mediaElement;
        let remoteStream;
        let peerConnection;
        let socket;
        let roomId = '';
        let isCaller = false;
        let audioStream;
        let animationId;
        
        // Configuration for WebRTC (using Google's public STUN server)
        const configuration = {
            iceServers: [
                { urls: 'stun:stun.l.google.com:19302' }
            ]
        };
        
        // DOM elements
        const pcStartBtn = document.getElementById('pc-start');
        const pcStopBtn = document.getElementById('pc-stop');
        const iphoneStartBtn = document.getElementById('iphone-start');
        const iphoneStopBtn = document.getElementById('iphone-stop');
        const joinRoomBtn = document.getElementById('join-room');
        const roomIdInput = document.getElementById('room-id');
        const connectionStatus = document.getElementById('connection-status');
        const volumeControl = document.getElementById('volume-control');
        const pcVisualizer = document.getElementById('pc-visualizer');
        const iphoneVisualizer = document.getElementById('iphone-visualizer');
        
        // Initialize Socket.io connection
        function initSocket() {
            // Connect to a signaling server (in a real app, replace with your server URL)
            socket = io('https://pist-backend.onrender.com', {
                transports: ['websocket'],
                upgrade: false
            });
            
            socket.on('connect', () => {
                updateConnectionStatus('Connected to server', 'text-green-400', 'fa-plug');
            });
            
            socket.on('disconnect', () => {
                updateConnectionStatus('Disconnected from server', 'text-red-400', 'fa-plug');
            });
            
            socket.on('room-created', (room) => {
                roomId = room;
                roomIdInput.value = room;
                isCaller = true;
                updateConnectionStatus(`Room ${room} created`, 'text-blue-400', 'fa-door-open');
            });
            
            socket.on('room-joined', (room) => {
                roomId = room;
                isCaller = false;
                updateConnectionStatus(`Joined room ${room}`, 'text-blue-400', 'fa-users');
            });
            
            socket.on('room-full', () => {
                alert('Room is full. Please try another room ID.');
            });
            
            socket.on('offer', (offer) => {
                if (!isCaller) {
                    handleOffer(offer);
                }
            });
            
            socket.on('answer', (answer) => {
                if (isCaller) {
                    handleAnswer(answer);
                }
            });
            
            socket.on('ice-candidate', (candidate) => {
                handleIceCandidate(candidate);
            });
        }
        
        // Join room function
        function joinRoom() {
            const room = roomIdInput.value.trim();
            if (!room) {
                alert('Please enter a room ID');
                return;
            }
            
            if (socket && socket.connected) {
                socket.emit('join-room', room);
            } else {
                alert('Not connected to server. Please try again.');
            }
        }
        
        // Update connection status UI
        function updateConnectionStatus(text, colorClass, iconClass) {
            connectionStatus.innerHTML = `
                <i class="fas ${iconClass} text-3xl ${colorClass}"></i>
                <p class="mt-2 ${colorClass}">${text}</p>
            `;
        }
        
        // Capture system audio (works in Chrome/Edge with experimental flag enabled)
        async function captureSystemAudio() {
            try {
                // Create audio context
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                
                // Create a media element that will play the system audio
                // In a real app, you would use the Web Audio API to capture system audio
                // This is a placeholder for the actual implementation
                mediaElement = new Audio();
                
                // Create a media stream destination node
                mediaStreamDestination = audioContext.createMediaStreamDestination();
                
                // Create a source from the media element
                const source = audioContext.createMediaElementSource(mediaElement);
                source.connect(mediaStreamDestination);
                
                // For demonstration, we'll use a silent audio file
                // In a real app, you would capture actual system audio
                mediaElement.src = 'data:audio/wav;base64,UklGRiQAAABXQVZFZm10IBAAAAABAAEARKwAAIhYAQACABAAZGF0YQAAAAA=';
                mediaElement.loop = true;
                
                // Start playing (silent audio)
                await mediaElement.play();
                
                // Get the stream from the destination node
                audioStream = mediaStreamDestination.stream;
                
                // Set up audio visualization for PC
                setupAudioVisualization(audioStream, pcVisualizer);
                
                return audioStream;
            } catch (error) {
                console.error('Error capturing system audio:', error);
                alert('Failed to capture system audio. Make sure you have enabled Experimental Web Platform Features in Chrome/Edge.');
                throw error;
            }
        }
        
        // Initialize WebRTC
        async function initWebRTC(isInitiator) {
            try {
                // Create peer connection
                peerConnection = new RTCPeerConnection(configuration);
                
                // Set up event handlers for ICE candidates
                peerConnection.onicecandidate = (event) => {
                    if (event.candidate) {
                        socket.emit('ice-candidate', {
                            room: roomId,
                            candidate: event.candidate
                        });
                    }
                };
                
                // Handle incoming tracks
                peerConnection.ontrack = (event) => {
                    remoteStream = new MediaStream([event.track]);
                    const audioElement = new Audio();
                    audioElement.srcObject = remoteStream;
                    audioElement.play();
                    
                    // Set up volume control
                    volumeControl.addEventListener('input', (e) => {
                        audioElement.volume = e.target.value;
                    });
                    
                    // Set up audio visualization for iPhone
                    setupAudioVisualization(remoteStream, iphoneVisualizer);
                };
                
                // If we're the caller, get system audio and create offer
                if (isInitiator) {
                    try {
                        // Capture system audio
                        const stream = await captureSystemAudio();
                        
                        // Add audio tracks to peer connection
                        stream.getTracks().forEach(track => {
                            peerConnection.addTrack(track, stream);
                        });
                        
                        // Create offer
                        const offer = await peerConnection.createOffer();
                        await peerConnection.setLocalDescription(offer);
                        
                        // Send offer to other peer
                        socket.emit('offer', {
                            room: roomId,
                            offer: offer
                        });
                    } catch (error) {
                        console.error('Error capturing system audio:', error);
                        alert('Failed to capture system audio. Make sure you have enabled Experimental Web Platform Features in Chrome/Edge.');
                        throw error;
                    }
                }
                
                return true;
            } catch (error) {
                console.error('WebRTC error:', error);
                alert('Error initializing WebRTC: ' + error.message);
                return false;
            }
        }
        
        // Handle incoming offer
        async function handleOffer(offer) {
            try {
                await peerConnection.setRemoteDescription(new RTCSessionDescription(offer));
                
                // Create answer
                const answer = await peerConnection.createAnswer();
                await peerConnection.setLocalDescription(answer);
                
                // Send answer to caller
                socket.emit('answer', {
                    room: roomId,
                    answer: answer
                });
                
                return true;
            } catch (error) {
                console.error('Error handling offer:', error);
                return false;
            }
        }
        
        // Handle incoming answer
        async function handleAnswer(answer) {
            try {
                await peerConnection.setRemoteDescription(new RTCSessionDescription(answer));
                return true;
            } catch (error) {
                console.error('Error handling answer:', error);
                return false;
            }
        }
        
        // Handle ICE candidate
        async function handleIceCandidate(candidate) {
            try {
                await peerConnection.addIceCandidate(new RTCIceCandidate(candidate));
            } catch (error) {
                console.error('Error adding ICE candidate:', error);
            }
        }
        
        // Set up audio visualization
        function setupAudioVisualization(stream, visualizerElement) {
            // Clear any existing visualization
            visualizerElement.innerHTML = '';
            
            // Create audio context if it doesn't exist
            if (!audioContext) {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
            }
            
            // Create analyser
            const analyser = audioContext.createAnalyser();
            analyser.fftSize = 64;
            const dataArray = new Uint8Array(analyser.frequencyBinCount);
            
            // Create source from stream
            const source = audioContext.createMediaStreamSource(stream);
            source.connect(analyser);
            
            // Create visualizer bars
            for (let i = 0; i < 20; i++) {
                const bar = document.createElement('div');
                bar.className = 'audio-bar';
                bar.style.left = `${i * 5}%`;
                bar.style.animationDelay = `${i * 0.05}s`;
                visualizerElement.appendChild(bar);
            }
            
            // Start animation if not already running
            if (!animationId) {
                animateVisualizer(analyser, dataArray, visualizerElement);
            }
        }
        
        // Animate visualizer bars
        function animateVisualizer(analyser, dataArray, visualizerElement) {
            analyser.getByteFrequencyData(dataArray);
            
            const bars = visualizerElement.querySelectorAll('.audio-bar');
            bars.forEach((bar, i) => {
                // Scale the height based on frequency data
                const index = Math.floor(i * (dataArray.length / bars.length));
                const value = dataArray[index] / 255;
                const height = value * 100;
                bar.style.height = `${height}%`;
            });
            
            animationId = requestAnimationFrame(() => animateVisualizer(analyser, dataArray, visualizerElement));
        }
        
        // Stop all streams and clean up
        function stopStreaming() {
            if (audioStream) {
                audioStream.getTracks().forEach(track => track.stop());
                audioStream = null;
            }
            
            if (remoteStream) {
                remoteStream.getTracks().forEach(track => track.stop());
                remoteStream = null;
            }
            
            if (peerConnection) {
                peerConnection.close();
                peerConnection = null;
            }
            
            if (mediaElement) {
                mediaElement.pause();
                mediaElement = null;
            }
            
            if (animationId) {
                cancelAnimationFrame(animationId);
                animationId = null;
            }
            
            // Clear visualizers
            pcVisualizer.innerHTML = '';
            iphoneVisualizer.innerHTML = '';
            
            // Reset buttons
            pcStartBtn.disabled = false;
            pcStopBtn.disabled = true;
            iphoneStartBtn.disabled = false;
            iphoneStopBtn.disabled = true;
        }
        
        // Event listeners
        document.addEventListener('DOMContentLoaded', () => {
            // Initialize socket connection
            initSocket();
            
            // Set up event listeners for buttons
            joinRoomBtn.addEventListener('click', joinRoom);
            
            pcStartBtn.addEventListener('click', async () => {
                pcStartBtn.disabled = true;
                pcStopBtn.disabled = false;
                
                const success = await initWebRTC(true);
                if (!success) {
                    pcStartBtn.disabled = false;
                    pcStopBtn.disabled = true;
                }
            });
            
            pcStopBtn.addEventListener('click', () => {
                stopStreaming();
            });
            
            iphoneStartBtn.addEventListener('click', async () => {
                iphoneStartBtn.disabled = true;
                iphoneStopBtn.disabled = false;
                
                const success = await initWebRTC(false);
                if (!success) {
                    iphoneStartBtn.disabled = false;
                    iphoneStopBtn.disabled = true;
                }
            });
            
            iphoneStopBtn.addEventListener('click', () => {
                stopStreaming();
            });
        });
    </script>
</body>
</html>
